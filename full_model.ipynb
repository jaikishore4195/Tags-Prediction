{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import FastText\n",
    "import keras\n",
    "import keras\n",
    "from copy import deepcopy\n",
    "import keras_contrib\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "from keras.models import load_model\n",
    "from gensim.models import Word2Vec\n",
    "import itertools\n",
    "from more_itertools import locate\n",
    "from keras.models import load_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_paras.txt','r') as f:\n",
    "    data=f.readlines()\n",
    "    \n",
    "for i in range(0,len(data)):\n",
    "    data[i]=data[i][2:].split(\"', '\")\n",
    "    data[i][-1]=data[i][-1].replace(\"']\\n\",'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"tags.pkl\", \"rb\") as fp:\n",
    "    tags = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13647276\n",
      "27286349\n",
      "40969093\n",
      "54709715\n",
      "68387947\n",
      "82038839\n",
      "95745378\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for i in range(0,len(data)):\n",
    "    if i%100000==0 and i!=0:\n",
    "        print(count)\n",
    "    count+=len(data[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107626405\n"
     ]
    }
   ],
   "source": [
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = 95745378\n",
    "end_index = 107626405"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[700000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('one_hot_target.txt','r') as f:\n",
    "    full_target=f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_target = full_target[start_index:end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=[]\n",
    "i=0\n",
    "k=0\n",
    "while(i<end_index - start_index):\n",
    "    new_sen=[]\n",
    "    for j in range(0,len(data[k])):\n",
    "        x=full_target[i+j].replace(\"[\",'')\n",
    "        x=x.replace(\"]\\n\",'')\n",
    "        x=x.split(' ')\n",
    "        x=[float(num) for num in x if num not in \"\"]\n",
    "        new_sen.append(x)\n",
    "    i+=len(data[k])\n",
    "    k+=1\n",
    "    target.append(np.array(new_sen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del full_target\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_target = []\n",
    "for i in range(len(target)):\n",
    "    temp = []\n",
    "    for j in range(len(target[i])):\n",
    "        temp.append(target[i][j][np.array([0,1,3,4])].tolist())\n",
    "    new_target.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del target\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_model = FastText.load('fasttext_big_new_test.model')\n",
    "w2v_model=Word2Vec.load('word2vec_big_new_test.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformation(x):\n",
    "    for i in range(len(x)):\n",
    "        x[i]=x[i][0:300]\n",
    "        leng=300-len(x[i])\n",
    "        x[i]=x[i]+leng*['pad']\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_fasttext(x):\n",
    "    for i in range(len(x)):\n",
    "        for j in range(300):\n",
    "                try:\n",
    "                    w2v = w2v_model.wv[x[i][j]]\n",
    "                except:\n",
    "                    w2v = np.zeros([150])\n",
    "                try:\n",
    "                    ft = fasttext_model.wv[x[i][j]]\n",
    "                except:\n",
    "                    ft = np.zeros([150])\n",
    "\n",
    "                x[i][j] = np.concatenate([w2v,ft])\n",
    "\n",
    "    \n",
    "    return np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = keras.layers.Input(shape=(300,300))\n",
    "lstm_1 = keras.layers.Bidirectional(keras.layers.CuDNNLSTM(units=128, return_sequences=True))(input_text)\n",
    "drop = keras.layers.Dropout(0.3)(lstm_1)\n",
    "dense = keras.layers.TimeDistributed(keras.layers.Dense(70, activation=\"relu\"))(drop)\n",
    "out=keras.layers.Dense(4,activation='softmax')(dense)\n",
    "\n",
    "model = keras.Model(inputs = input_text,outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('final_single_tags_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elmoembedding(x):\n",
    "    x = transformation(x)\n",
    "    y = embed_fasttext(deepcopy(x))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_processing(x):\n",
    "    for i in range(len(x)):\n",
    "        x[i] = x[i][0:300]\n",
    "        for j in range(0,(300 - len(x[i]))):\n",
    "            x[i] = np.vstack([x[i],np.array([1,0,0,0])])\n",
    "    return np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(batch_size,from_list_x,from_list_y):\n",
    "\n",
    "    assert len(from_list_x) == len(from_list_y)\n",
    "    total_size = len(from_list_x)\n",
    "\n",
    "    while True:\n",
    "\n",
    "        for i in range(0,total_size,batch_size):\n",
    "            yield np.array(elmoembedding(deepcopy(from_list_x[i:i+batch_size]))),target_processing((deepcopy(from_list_y[i:i+batch_size])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1360/1359 [==============================] - 514s 378ms/step - loss: 0.0435\n",
      "Epoch 2/4\n",
      "1360/1359 [==============================] - 661s 486ms/step - loss: 0.0421\n",
      "Epoch 3/4\n",
      "1360/1359 [==============================] - 499s 367ms/step - loss: 0.0412\n",
      "Epoch 4/4\n",
      "1360/1359 [==============================] - 695s 511ms/step - loss: 0.0405\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26be19c8f60>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator=generator(64,data,new_target),epochs=4,steps_per_epoch=len(data)/64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('final_single_tags_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = list(itertools.chain.from_iterable(tags))\n",
    "\n",
    "dictionary_tags={}\n",
    "for i in range(0,len(merged)):\n",
    "    try:\n",
    "        dictionary_tags[merged[i]]+=1\n",
    "    except:\n",
    "        dictionary_tags[merged[i]]=1\n",
    "        \n",
    "sorted_by_value = sorted(dictionary_tags.items(), key=lambda kv: kv[1],reverse=True)\n",
    "\n",
    "set_of_all_tags=[]\n",
    "for i in range(0,len(sorted_by_value)):\n",
    "    if sorted_by_value[i][0] not in set_of_all_tags:\n",
    "        set_of_all_tags.append(sorted_by_value[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def look_up_two(word,para):\n",
    "    for i in range(0,len(set_of_all_tags)):\n",
    "        x=set_of_all_tags[i].split('-')\n",
    "        \n",
    "        if len(x)==2 and word==x[0] and x[1] in para:\n",
    "            return [set_of_all_tags[i]]\n",
    "        if len(x)==2 and word==x[1] and x[0] in para:\n",
    "            return [set_of_all_tags[i]]\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def look_up_three(word,para):\n",
    "    for i in range(0,len(set_of_all_tags)):\n",
    "        x=set_of_all_tags[i].split('-')\n",
    "        \n",
    "        if len(x)==3 and word==x[0] and x[1] in para and x[2] in para:\n",
    "            return [set_of_all_tags[i]]\n",
    "        if len(x)==3 and word==x[1] and x[0] in para and x[2] in para:\n",
    "            return [set_of_all_tags[i]]\n",
    "        if len(x)==3 and word==x[2] and x[0] in para and x[1] in para:\n",
    "            return [set_of_all_tags[i]]\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(pred_data):\n",
    "    \n",
    "    dat = elmoembedding(deepcopy(pred_data))\n",
    "    result = model.predict(dat)\n",
    "    \n",
    "    new_res=[]\n",
    "    for i in range(0,len(result)):\n",
    "        pred_data[i]=np.array(pred_data[i])\n",
    "        res=[]\n",
    "        for j in range(0,len(result[i])):\n",
    "            res.append(np.argmax(result[i][j]))\n",
    "        new_res.append(res) \n",
    "        \n",
    "    del result\n",
    "    \n",
    "    main_tags = []\n",
    "    \n",
    "    for i in range(0,len(new_res)):\n",
    "        main_tags.append(pred_data[i][np.where(np.array(new_res[i])==1)[0]])\n",
    "        \n",
    "    \n",
    "    two_tags_all=[]\n",
    "    for i in range(0,len(new_res)):\n",
    "        two_tags_words=pred_data[i][np.where(np.array(new_res[i])==2)[0]]\n",
    "        two_tags_temp=[]\n",
    "        for j in range(0,len(two_tags_words)):\n",
    "            two_tags_temp+=look_up_two(two_tags_words[j],pred_data[i])\n",
    "        two_tags_all.append(two_tags_temp)\n",
    "            \n",
    "        \n",
    "    three_tags_all=[]\n",
    "    for i in range(0,len(new_res)):\n",
    "        three_tags_words=pred_data[i][np.where(np.array(new_res[i])==3)[0]]\n",
    "        three_tags_temp=[]\n",
    "        for j in range(0,len(three_tags_words)):\n",
    "            three_tags_temp+=look_up_three(three_tags_words[j],pred_data[i])\n",
    "        three_tags_all.append(three_tags_temp)\n",
    "    \n",
    "    full_tags=[]\n",
    "    for i in range(0,len(pred_data)):        \n",
    "        full = list(main_tags[i]) +two_tags_all[i]+three_tags_all[i] \n",
    "        full_tags.append(list(set(full)))\n",
    "    \n",
    "    \n",
    "    return full_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1score(pred,actual):\n",
    "    inter=0\n",
    "    for i in range(len(pred)):\n",
    "        inter=len(list(set(actual).intersection(pred)))\n",
    "    try:\n",
    "        precision=inter/len(pred)\n",
    "    except ZeroDivisionError:\n",
    "        precision=0\n",
    "    recall=inter/len(actual)\n",
    "    \n",
    "    try:\n",
    "        to_return=((2*recall*precision)/(recall+precision))\n",
    "    except ZeroDivisionError:\n",
    "        to_return=0\n",
    "    return to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_predictions():\n",
    "    i=0\n",
    "    predicted_tags=[]\n",
    "    while(i<len(x_test)):\n",
    "        pred=predict(x_test[i:i+64])\n",
    "        for j in range(0,len(pred)):\n",
    "            if 'angular' in pred[j]:\n",
    "                ind=pred[j].index('angular')\n",
    "                pred[ind]=['angularjs']\n",
    "            if 'ruby' in pred[j]:\n",
    "                ind=pred[j].index('ruby')\n",
    "                pred[ind]=['ruby-on-rails']\n",
    "            if 'node' in pred[j]:\n",
    "                ind=pred[j].index('node')\n",
    "                pred[ind]=['node.js']\n",
    "            if 'react' in pred[j]:\n",
    "                ind=pred[j].index('react')\n",
    "                pred[ind]=['reactjs']\n",
    "            if 'psql' in pred[j]:\n",
    "                ind=pred[j].index('psql')\n",
    "                pred[ind]=['postgresql']\n",
    "            if 'python3' in pred[j]:\n",
    "                ind=pred[j].index('python3')\n",
    "                pred[ind]=['python-3.x']\n",
    "            \n",
    "            \n",
    "        i+=64\n",
    "        predicted_tags+=pred\n",
    "    \n",
    "    predicted_tags = codes_func(predicted_tags)\n",
    "    \n",
    "    for i in range(len(predicted_tags)):\n",
    "        predicted_tags[i] = list(set(predicted_tags[i]))\n",
    "        predicted_tags[i] = [i for i in predicted_tags[i] if i !='angular']\n",
    "        predicted_tags[i] = [i for i in predicted_tags[i] if i !='ruby']\n",
    "        predicted_tags[i] = [i for i in predicted_tags[i] if i !='node']\n",
    "        predicted_tags[i] = [i for i in predicted_tags[i] if i !='react']\n",
    "        predicted_tags[i] = [i for i in predicted_tags[i] if i !='psql']\n",
    "        \n",
    "    avg_f1=0\n",
    "    for i in range(0,len(x_test)):\n",
    "        avg_f1+=f1score(predicted_tags[i],tags_test[i])\n",
    "    return (avg_f1/len(x_test)),predicted_tags[0:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes_tag=[]\n",
    "for i in range(0,len(tags_test)):\n",
    "    try:\n",
    "        codes_tag.append(tags_test[i][0])\n",
    "    except IndexError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"vectorizer_1.pkl\", \"rb\") as fp:\n",
    "    vectorizer_1 = pickle.load(fp)\n",
    "with open(\"vectorizer_2.pkl\", \"rb\") as fp:\n",
    "    vectorizer_2 = pickle.load(fp)\n",
    "with open(\"model_codes_1.pkl\", \"rb\") as fp:\n",
    "    model_1 = pickle.load(fp)\n",
    "with open(\"model_codes_2.pkl\", \"rb\") as fp:\n",
    "    model_2 = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.predict_proba(vectorizer_2.transform([' '.join(x_tes)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def codes_func(predicted_tags):\n",
    "    for i in range(0,len(x_test)):\n",
    "        prob1=model_1.predict_proba(vectorizer_1.transform([' '.join(x_test[i])]))\n",
    "        prob2=model_2.predict_proba(vectorizer_2.transform([' '.join(x_test[i])]))\n",
    "        ind1=np.argmax(prob1)\n",
    "        ind2=np.argmax(prob2)\n",
    "        if prob1[0][ind1]>0.40:\n",
    "            predicted_tags[i].append((model_1.predict(vectorizer_1.transform([' '.join(x_test[i])]))[0]))\n",
    "        elif prob2[0][ind2]>0.60:\n",
    "            predicted_tags[i].append((model_2.predict(vectorizer_2.transform([' '.join(x_test[i])]))[0]))\n",
    "        predicted_tags[i] = list(set(predicted_tags[i]))\n",
    "    return predicted_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['flash', 'http', 'websocket', 'communication', 'wireshark'],\n",
       " ['sql', 'postgresql', 'offset'],\n",
       " ['php', 'permissions', 'binary', 'bit-manipulation'],\n",
       " ['reactjs'],\n",
       " ['javascript', 'node.js', 'websocket', 'rpc', 'promise'],\n",
       " ['android'],\n",
       " ['java'],\n",
       " ['c++', 'c', 'opencl', 'fractals', 'newtons-method'],\n",
       " ['visual-studio-2013', 'web-deployment-project'],\n",
       " ['android'],\n",
       " ['logging', 'nlog'],\n",
       " ['regex', 'download', 'wget'],\n",
       " ['javascript', 'performance', 'highcharts'],\n",
       " ['macos', 'bash', 'command-line', 'command-line-arguments'],\n",
       " ['mysql', 'cakephp', 'sql-update', 'cakephp-2.0'],\n",
       " ['php', 'html', 'css', 'twitter'],\n",
       " ['c#', 'azure'],\n",
       " ['python', 'notepad++'],\n",
       " ['java', 'linux'],\n",
       " ['javascript', 'php', 'charts', 'google-visualization'],\n",
       " ['linux', 'assembly'],\n",
       " ['java', 'object', 'arraylist', 'abstract-class', 'extends'],\n",
       " ['java', 'eclipse', 'postgresql', 'jpa', 'persistence'],\n",
       " ['colors', 'leaflet'],\n",
       " ['java', 'mysql', 'java-ee', 'jdbc'],\n",
       " ['css3', 'css-animations'],\n",
       " ['c', 'linux', 'ubuntu', 'linux-kernel', 'setuid'],\n",
       " ['asp.net-web-api', 'odata'],\n",
       " ['c#', 'entity-framework', 'entity-framework-4', 'code-first'],\n",
       " ['javascript', 'jquery', 'ajax', 'asynchronous'],\n",
       " ['linux', 'bash', 'awk'],\n",
       " ['html', 'twitter-bootstrap', 'twitter-bootstrap-3'],\n",
       " ['ruby-on-rails'],\n",
       " ['c++', 'design-patterns', 'filter', 'decorator', 'proxy-pattern'],\n",
       " ['c++'],\n",
       " ['ruby-on-rails', 'rspec'],\n",
       " ['c#'],\n",
       " ['meteor', 'meteor-blaze'],\n",
       " ['java'],\n",
       " ['windows', 'winapi', 'winlogon'],\n",
       " ['ruby-on-rails', 'google-drive-sdk'],\n",
       " ['javascript', 'php', 'jquery', 'mysql', 'angularjs'],\n",
       " ['javascript', 'jquery', 'css', 'animation'],\n",
       " ['sql'],\n",
       " ['ios', 'xcode', 'cocoapods'],\n",
       " ['javascript', 'html', 'angularjs'],\n",
       " ['ios', 'push-notification'],\n",
       " ['ios', 'external-accessory', 'mfi', 'midi-interface'],\n",
       " ['xml', 'android-layout', 'layout'],\n",
       " ['gwt']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
